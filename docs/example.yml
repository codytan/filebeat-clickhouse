filebeat.inputs:
- type: filestream
  id: test-log-id
  enabled: true
  fields: 
    table: "table_name" #clickhouse table name
  paths:
    - ./test.log*
- type: filestream
  id: test-log-id2
  enabled: true
  fields: 
    table: "table_name2" #another table 
  paths:
    - ./test2.log*

output.clickhouse:
  host: ["127.0.0.1:9000"] #clickhouse host
  db: "default" #database
  user_name: "default" 
  pass_word: ""
  batch_size: 1000
  max_retries: 5
  tables: #insert data config, specify the table and columns. Need to be exactly the same as the field in log file(JSON row format), for compatibility with data types with SQL, the JSON field must be string type
    - table: "table_name"
      columns: ["EventTime", "Label.Label", "Label.Count"] #suport nested type
    - table: "table_name2"
      columns: ["id", "name"]

queue.mem:
  events: 4096
  flush.min_events: 1000 #send event num per batch
  flush.timeout: 5s #send event interval
